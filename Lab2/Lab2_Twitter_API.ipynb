{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab 2- Twitter API.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/michellekan/smt203/blob/main/Lab2/Lab2_Twitter_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKVp54FJN2Do"
      },
      "source": [
        "# Lab 2 - Twitter API (v2)\n",
        "\n",
        "In this lab, you will learn how to retrieve tweets data from Twitter by using an open source library called [Tweepy](https://docs.tweepy.org/en/latest/). Tweepy gives you a very convenient way to access the Twitter API with Python.  \n",
        "\n",
        "Also, check the official [Twitter API](https://developer.twitter.com/en/docs/twitter-api/getting-started/guide).\n",
        "\n",
        "This lab is written by Michelle KAN (michellekan@smu.edu.sg) and Jisun AN (jisunan@smu.edu.sg). \n",
        "\n",
        "Let's first install the tweepy library:<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riNSHhDAN2Du",
        "scrolled": true
      },
      "source": [
        "## This it OPTIONAL if you are running the current notebook using Google Colab\n",
        "!pip install tweepy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnKJQw2xN2Dv"
      },
      "source": [
        "## 1) Authentication\n",
        "\n",
        "The following code imports the tweepy library and other required libraries. Twitter API uses the [tweepy.AuthHandler](https://docs.tweepy.org/en/v3.5.0/auth_tutorial.html) class for authentication. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MsX2ofHN2Dw"
      },
      "source": [
        "import tweepy\n",
        "from tweepy import OAuthHandler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLfR_UPZN2Dw"
      },
      "source": [
        "Before using the Twitter API, you will need a Twitter account, and to have obtained Twitter API authentication credentials.<br>Set your authentication credentials below. <br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZG3CTaj_N2Dx"
      },
      "source": [
        "# Consumer/Access key/secret/token obtained from Twitter\n",
        "# You should have created a Twitter app and gotten these keys.\n",
        "# Do NOT share your key/secret/token with other students.\n",
        "consumer_key    = ''\n",
        "consumer_secret = ''\n",
        "access_token    = ''\n",
        "access_secret   = ''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMYJNw7KN2Dx"
      },
      "source": [
        "The following code creates an authorization object with your above authentication info and calls the Twitter's API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZBc-9SfN2Dz"
      },
      "source": [
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_secret)\n",
        "\n",
        "# This line finally calls Twitter's Rest API.\n",
        "api = tweepy.API(auth)\n",
        "#api = tweepy.API(auth,wait_on_rate_limit=True, wait_on_rate_limit_notify=True)\n",
        "\n",
        "# The following codes verify if the authentication is successful\n",
        "# If all goes well, you should see a message saying Authentication OK.\n",
        "# Otherwise, check your Consumer/Access key/secret/token\n",
        "try:\n",
        "    api.verify_credentials()\n",
        "    print(\"Authentication OK\")\n",
        "except:\n",
        "    print(\"Error during authentication\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jam99XujaXu7"
      },
      "source": [
        "## 2) Types of Twitter API & Tweepy Cursor\n",
        "\n",
        "### 2-1) Twitter REST API\n",
        "\n",
        "The REST API is to pull data from Twitter. \n",
        "\n",
        "We can do retrieve tweets based on query or tweets of all users using `tweepy.Cursor.` \n",
        "\n",
        "`tweepy.Cursor` method deals with the pagination -- if there's many tweets returned, it makes it easy to iterate the data.\n",
        "\n",
        "\n",
        "#### a) Search tweets\n",
        "\n",
        "Below will return five tweets containing search words \n",
        "\n",
        "```\n",
        "search_words = 'covid'\n",
        "max_tweets = 5\n",
        "tweets = tweepy.Cursor(api.search, q=search_words, tweet_mode='extended').items(max_tweets)\n",
        "```\n",
        "\n",
        "\n",
        "#### b) Users tweets\n",
        "\n",
        "Below will return 5 tweets posted by BiilGates\n",
        "\n",
        "```\n",
        "username = 'BillGates'\n",
        "max_tweets = 5\n",
        "tweets = tweepy.Cursor(api.user_timeline, id=username, tweet_mode='extended').items(max_tweets)\n",
        "```\n",
        "\n",
        "\n",
        "### 2-2) Streaming API tweets\n",
        "The Twitter streaming API is used to download twitter messages in real time. It is useful for obtaining a high volume of tweets, or for creating a live feed using a site stream or user stream. See the [Twitter Streaming API Documentation](https://developer.twitter.com/en/docs/tweets/filter-realtime/overview).\n",
        "\n",
        "```\n",
        "keyword = 'covid'\n",
        "myStream.filter(track=[keyword])\n",
        "```\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIg2gAt3N2D1"
      },
      "source": [
        "## 3) Search Tweets\n",
        "\n",
        "Now you are ready to search Twitter for recent tweets! \n",
        "\n",
        "\n",
        " \n",
        "### a) Search Tweets using Keywords\n",
        "\n",
        "\n",
        "To create this query, you will define the:\n",
        "- Search term \n",
        "- start date of your search (optional)\n",
        " \n",
        "Note: Search API returns tweets with specific search terms, posted in the last 7 days. You need a premium account for going further than 7 days. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afCa3u2vN2D0"
      },
      "source": [
        "(Optional) Uncomment and run the following code snippet if you wish to enable Python logging to know what's happening underlying in the API call."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocLOaD9zN2D0"
      },
      "source": [
        "# import logging\n",
        "# logging.basicConfig(level=logging.DEBUG,\n",
        "#                     format='%(asctime)s %(name)-12s %(levelname)-8s %(message)s',\n",
        "#                     datefmt='%m-%d %H:%M:%S')\n",
        "# logger = logging.getLogger(__name__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Ejl9xb7PW2v"
      },
      "source": [
        "# Define the search term and the date_since date as variables\n",
        "search_words = 'covid'\n",
        "date_since = \"2021-08-25\" #if you want to collect data from yesterday\n",
        "\n",
        "max_tweets = 5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db16LM5TN2D1"
      },
      "source": [
        "Below we use `tweepy.Cursor()` to search for tweets containing the specified search_words and perform pagination. Parameters:\n",
        "-   `api.search` – tweepy api method that returns a collection of relevant Tweets matching a specified query\n",
        "- \t`q` – the search query string of 500 characters maximum, including operators. Queries may additionally be limited by complexity.\n",
        "-   `lang` – restricts tweets to the given language\n",
        "-   `since` – returns tweet created on or after this date. Date should be formatted as YYYY-MM-DD.\n",
        "\n",
        "You can restrict the number of tweets returned by specifying a number in the `.items()` method. `.items(5)` will return 5 of the most recent tweets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twLFHAVlZzPP"
      },
      "source": [
        "# Below will return five tweets containing search words \n",
        "tweets = tweepy.Cursor(api.search, q=search_words, tweet_mode='extended').items(max_tweets)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-brNt50TN2D2"
      },
      "source": [
        "# You can add other parameters like lang, since, etc) \n",
        "tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\", since=date_since, tweet_mode='extended').items(max_tweets)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "chixNUKMN2D2"
      },
      "source": [
        "`tweets.Cursor()` returns an object `ItemIterator` that you can iterate to access the tweet data collected. Each tweet item in the iterator has various attributes including:\n",
        "\n",
        "- the text of the tweet\n",
        "- the date the tweet was sent\n",
        "- and more. \n",
        "\n",
        "The code below loops through the object and prints the text associated with each tweet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nugg_TxHo6dL"
      },
      "source": [
        "tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\", since=date_since, tweet_mode='extended').items(max_tweets)\n",
        "\n",
        "# Iterate tweets\n",
        "for tweet in tweets:\n",
        "\n",
        "    # print out user's screen name & tweet text\n",
        "    print(\"----------------------------------------------------\")\n",
        "    print ('Tweet ID ' + str(tweet.id))\n",
        "    print ('Created at ' + str(tweet.created_at))\n",
        "    \n",
        "    # Extracting tweet text when in Extended Mode\n",
        "    try: # If it's Retweet\n",
        "        text = tweet.retweeted_status.full_text\n",
        "    except AttributeError:  # Not a Retweet\n",
        "        text = tweet.full_text\n",
        "    print('\\t Tweet: ' + text)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-Bv1I7gN2D3"
      },
      "source": [
        "#### <img align=\"left\" src=\"https://docs.google.com/uc?id=1m3oi2yHQnNISJ5EhmWVhRsqPFao6qSU4\" width=\"50\"/><br><br>Who is Tweeting About 'covid'?\n",
        "\n",
        "You can access a wealth of information associated with each tweet. \n",
        "\n",
        "Below is an example of accessing information of users who are sending the tweets including users' screen name and their locations. Note that user locations are manually entered into Twitter by the user. Thus, you will see a lot of variation in the format of this value.\n",
        "\n",
        "- tweet.user.screen_name provides the user’s twitter handle associated with each tweet.\n",
        "- tweet.user.location provides the user’s provided location.\n",
        "\n",
        "You can try to include other items available within each tweet by checking out the [twitter developer documentation](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybY9g0hJm8n_",
        "scrolled": false
      },
      "source": [
        "tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\", since=date_since, tweet_mode='extended').items(max_tweets)\n",
        "\n",
        "for tweet in tweets:\n",
        "    print(\"----------------------------------------------------\")\n",
        "    print ('Tweet ID ' + str(tweet.id))\n",
        "    print (f'Tweeted by: @{tweet.user.screen_name} Created at: {str(tweet.created_at)} Location: {tweet.user.location}' )\n",
        "    # Extract text when in Extended Mode\n",
        "    try: # If it's Retweet\n",
        "        text = tweet.retweeted_status.full_text\n",
        "    except AttributeError:  # Not a Retweet\n",
        "        text = tweet.full_text\n",
        "    print('\\t' + text)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWBj4H83nf85"
      },
      "source": [
        "#### Save Tweets in a JSON format into a File\n",
        "\n",
        "\n",
        "Twitter API has limits in how many times we can call APIs to collect the data (Twitter Rate Limit). So, it's always better to save the data in the file. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsp2KB43qTwT"
      },
      "source": [
        "What is JSON? \n",
        "\n",
        "JavaScript Object Notation (JSON) is a standard text-based format for representing structured data based on JavaScript object syntax.\n",
        "\n",
        "Table / Database --> Text format\n",
        "\n",
        "| id        | name           | tweet  |\n",
        "| ------------- |:-------------:| -----:|\n",
        "| 123      | Jisun | Hello |\n",
        "| 456      | Michelle      |  Welcome |\n",
        "\n",
        "JSON\n",
        "`[{'id':123, 'name':'Jisun', 'tweet':'Hello'},{'id':456, 'name':'Michelle', 'tweet':'Welcome'}]`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMzh9Dbu9pAd"
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpjscjoG9pAd"
      },
      "source": [
        "# 'mypath' variable can be changed to your local path or Google Drive path\n",
        "mypath = \".\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oHn7Fgkm-e9"
      },
      "source": [
        "tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\", since=date_since, tweet_mode='extended').items(max_tweets)\n",
        "# Write data into a file\n",
        "filename = f\"{mypath}/tweets_{search_words}.jsons\"\n",
        "with open(filename, \"w\") as output:\n",
        "    for tweet in tweets:\n",
        "        myjson = tweet._json\n",
        "        output.write(json.dumps(myjson)+\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mK6ab00Zp2G7"
      },
      "source": [
        "Read tweets from the file.\n",
        "\n",
        "Let's read the first tweet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lHp8kO02p0gR"
      },
      "source": [
        "# Read data from a file\n",
        "filename = f\"{mypath}/tweets_{search_words}.jsons\"\n",
        "\n",
        "with open(filename) as fi:\n",
        "    for line_cnt, line in enumerate(fi):\n",
        "        tweet = json.loads(line.strip())\n",
        "        break # Break here so that we read the first line of the file\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "adG1FgMGqHvB"
      },
      "source": [
        "# Print JSON formated text in pretty way\n",
        "import pprint\n",
        "\n",
        "pprint.pprint(tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q57bFeKOp7OX"
      },
      "source": [
        "# Check keys in json\n",
        "tweet.keys()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-gdr9UZSq8y_"
      },
      "source": [
        "# How to access values in json\n",
        "print(tweet['id'])\n",
        "print(tweet['user']['name'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aQmweDFR9pAf"
      },
      "source": [
        "#### Extract data from json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHv_zg7jjord"
      },
      "source": [
        "# Read data from a file\n",
        "filename = f\"{mypath}/tweets_{search_words}.jsons\"\n",
        "\n",
        "with open(filename) as fi:\n",
        "    for line_cnt, line in enumerate(fi):\n",
        "        tweet = json.loads(line.strip())\n",
        "\n",
        "        tweetid = tweet['id']\n",
        "        created_at = tweet['created_at']\n",
        "\n",
        "        # Extract text from tweets in Extended Mode\n",
        "        if 'retweeted_status' in tweet: # If it's Retweet\n",
        "            text = tweet['retweeted_status']['full_text']\n",
        "        else:  # Not a Retweet\n",
        "            text = tweet['full_text']\n",
        "\n",
        "        user_screen_name = tweet['user']['screen_name']\n",
        "        user_location = tweet['user']['location']\n",
        "\n",
        "        print(\"--------------------------\")\n",
        "        print (f'Tweet ID: {tweetid}')\n",
        "        print (f'Tweeted by: @{user_screen_name}, Created at {created_at}, User Location: {user_location}' )\n",
        "        print(f'\\t {text}')\n",
        "\n",
        "        break #If you want to read other lines, comment this out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lk_6twn8N2D4"
      },
      "source": [
        "### Exercise 1\n",
        "\n",
        "Using the tweets retrieval code example given above, add on the following details for each tweet retrieved:\n",
        "- Number of times the Tweet has been retweeted (a retweet is when someone shares someone else’s tweet.)\n",
        "- Source/application used to post the Tweet.\n",
        "- User's name and friends count in Twitter\n",
        "\n",
        "You may take reference to the [twitter developer documentation](https://developer.twitter.com/en/docs/twitter-api/v1/data-dictionary/object-model/tweet). \n",
        "\n",
        "An example of the expected tweet output is given as follows: the tweet has been retweeted 21 times, the tweet has been posted using 'Twitter for Android' and user 'Cotonete' has 82 friends in Twitter:<br>\n",
        "<img align=\"center\" src='https://drive.google.com/uc?export=view&id=1WHGR9Q9ou4_w_zMhioEfVyhV1VxYNenk' style=\"height: 110px;\">\n",
        "\n",
        "As shown above there could be two ways to get this done. You can use Tweepy API or you can use the saved file. \n",
        "\n",
        "Try both!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9a8JQZPPN2D4"
      },
      "source": [
        "## Enter your code below using Tweepy API\n",
        "\n",
        "tweets = tweepy.Cursor(api.search, q=search_words, lang=\"en\", since=date_since, tweet_mode='extended').items(max_tweets)\n",
        "\n",
        "# Iterate tweets\n",
        "for tweet in tweets:\n",
        "    # print out user's screen name & tweet text\n",
        "    print(\"--------------------------\")    \n",
        "    print (f'Tweeted by: @{tweet.user.screen_name} Created at: {str(tweet.created_at)} Location: {tweet.user.location}' )\n",
        "    # Extract text when in Extended Mode\n",
        "    try: # If it's Retweet\n",
        "        text = tweet.retweeted_status.full_text\n",
        "    except AttributeError:  # Not a Retweet\n",
        "        text = tweet.full_text\n",
        "    print('\\t' + text)\n",
        "    \n",
        "    print(f'Retweeted: {tweet.retweet_count}times')\n",
        "    print(f'Posted using: {tweet.source}')\n",
        "    print(f'{tweet.user.screen_name} has {tweet.user.friends_count} friends')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGHKW63LwYqX"
      },
      "source": [
        "## Enter your code below using the saved file\n",
        "\n",
        "filename = f\"{mypath}/tweets_{search_words}.jsons\"\n",
        "\n",
        "with open(filename) as fi:\n",
        "    for line_cnt, line in enumerate(fi):\n",
        "        tweet = json.loads(line.strip())\n",
        "\n",
        "        tweetid = tweet['id']\n",
        "        created_at = tweet['created_at']\n",
        "\n",
        "        # Extract text from tweets in Extended Mode\n",
        "        if 'retweeted_status' in tweet: # If it's Retweet\n",
        "            text = tweet['retweeted_status']['full_text']\n",
        "        else:  # Not a Retweet\n",
        "            text = tweet['full_text']\n",
        "\n",
        "        user_screen_name = tweet['user']['screen_name']\n",
        "        user_location = tweet['user']['location']\n",
        "\n",
        "        friends_count = tweet['user']['friends_count']\n",
        "        source = tweet['source']\n",
        "        retweet_count = tweet['retweet_count']\n",
        "\n",
        "        print(\"--------------------------\")\n",
        "        print (f'Tweet ID: {tweetid}')\n",
        "        print (f'Tweeted by: @{user_screen_name}, Created at {created_at}, Location: {user_location}' )\n",
        "        print(f'\\t {text}')\n",
        "        print(f'Retweeted: {retweet_count}times')\n",
        "        print(f'Posted using: {source}')\n",
        "        print(f'{user_screen_name} has {friends_count} friends')\n",
        "\n",
        "        break #If you want to read other lines, comment this out\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WcJviiCN2D5"
      },
      "source": [
        "#### Removing Retweets\n",
        "\n",
        "In the above example, some of the tweets retrieved may contain prefix 'RT' which means they are retweets. A retweet is when someone shares someone else’s tweet. It is similar to sharing in Facebook. Sometimes you may want to remove retweets as they contain duplicate content that might skew your analysis if you are only looking at word frequency. Other times, you may want to keep retweets.\n",
        "\n",
        "Below you ignore all retweets by adding `-filter:retweets` to your query. You may wish to check out the [Twitter API](https://docs.tweepy.org/en/latest/api.html) documentation on other ways to customize your queries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5C8b-izN2D5",
        "scrolled": false
      },
      "source": [
        "new_search = search_words + \" -filter:retweets\" \n",
        "# new_search has the value \"clean energy -filter:retweets\"\n",
        "\n",
        "tweets = tweepy.Cursor(api.search,q=new_search, lang=\"en\",since=date_since).items(8)\n",
        "\n",
        "for tweet in tweets:\n",
        "    print(\"----------------------------------------------------\")\n",
        "    print (f'Tweeted by: @{tweet.user.screen_name} Created at: {str(tweet.created_at)} Location: {tweet.user.location}' )\n",
        "    print(f'\\tText: {tweet.text}')\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M76tDLKeN2D5"
      },
      "source": [
        "### Create a Pandas Dataframe From A List of Tweet Data\n",
        "\n",
        "Instead of displaying on screen, you can also populate a pandas dataframe using tweets data retrieved.\n",
        "\n",
        "[Pandas](https://pandas.pydata.org/) are widely used libraries to support handling tabular data. \n",
        "I can say that pandas is the defacto standard libarary.\n",
        "Let's import pandas.\n",
        "\n",
        "As typing 'pandas' is hard (...), in most cases, pandas is imported like below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2DGXbMKPW24"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7gabRHePW24"
      },
      "source": [
        "Then, you can create pandas data frame from collected data.\n",
        "\n",
        "You first append your data as a list, then conver it to dataframe.\n",
        "\n",
        "You can imagine that the dataframe is a table. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPZl5GzYN2D6"
      },
      "source": [
        "# setting parameters and retrieving tweets\n",
        "new_search = search_words + \" -filter:retweets\" \n",
        "tweets = tweepy.Cursor(api.search,q=new_search, lang=\"en\",since=date_since,tweet_mode='extended').items(8)\n",
        "\n",
        "## initialise list to be used to store tweets retrieved\n",
        "tweets_list = []\n",
        "\n",
        "## appending tweets retrieved into a list\n",
        "for tweet in tweets:\n",
        "    \n",
        "    try: # If it's Retweet\n",
        "        text = tweet.retweeted_status.full_text\n",
        "    except AttributeError:  # Not a Retweet\n",
        "        text = tweet.full_text\n",
        "\n",
        "    tweets_list.append([tweet.user.screen_name, tweet.created_at, tweet.user.location, text])\n",
        "\n",
        "# populate dataframe with list of tweets\n",
        "tweet_df = pd.DataFrame(data=tweets_list, columns=['user','created_at','location','text'])\n",
        "tweet_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BRZaiiLN2D6"
      },
      "source": [
        "## save the data into a csv file\n",
        "tweet_df.to_csv('covid_tweet.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEOMgZPPPW25"
      },
      "source": [
        "### Pandas basic \n",
        "\n",
        "(You can skip this sub-section if you are already familiar with Pandas.) \n",
        "\n",
        "Let's read csv file using pandas. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srDKXyeXPW25"
      },
      "source": [
        "## By default, read_csv() function assumes that the separator as ','. Thus, we can omit it as well. \n",
        "df = pd.read_csv('covid_tweet.csv', sep=',')\n",
        "df.head(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ifegmrRPW25"
      },
      "source": [
        "You can also see the n rows from the bottom by tail()."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQbfSuFxPW25"
      },
      "source": [
        "df.tail(n=5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QHPwFEk9PW25"
      },
      "source": [
        "You can check the number of rows and columns by .shape\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STEFYfXzPW25"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rAZUvpVAPW26"
      },
      "source": [
        "## below if how you can access the values of df.shape \n",
        "print (f'{df.shape[0]} rows and {df.shape[1]} columns')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOFF8s0kPW26"
      },
      "source": [
        "We will work with pandas more later in this lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EyMvH1JoN2D7"
      },
      "source": [
        "### Search Tweets by Specific User\n",
        "\n",
        "Besides keyword, we can also retrieve tweets posted by specific Twitter user. \n",
        "\n",
        "Parameters:\n",
        "-   `api.user_timeline` – tweepy api method that returns the most recent statuses (up to 20) posted from the user specified.\n",
        "-   `id` – unique user ID or screen name of a user\n",
        "-   `lang` – restricts tweets to the given language\n",
        "-   `include_rts` – boolean indicator to specify whether to include retweets\n",
        "-   `exclude_replies` – boolean indicator to specify whether to exclude tweet replies\n",
        "\n",
        "Similarly, you can restrict the number of tweets returned by specifying a number in the `.items()` method. `.items(10)` will return 10 of the most recent tweets.\n",
        "\n",
        "Let's look at the following example that retrieves tweets posted by UK Model World Health Organization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKw8Kp68N2D7"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "user_id = \"UKModelWHO\"\n",
        "\n",
        "## initialise list to be used to store tweets retrieved\n",
        "tweets_list = []\n",
        "\n",
        "## appending tweets retrieved into a list\n",
        "for tweet in tweepy.Cursor(api.user_timeline, id=user_id ,lang=\"en\", include_rts=False, exclude_replies=True, tweet_mode='extended').items(10):\n",
        "    try: # If it's Retweet\n",
        "        text = tweet.retweeted_status.full_text\n",
        "    except AttributeError:  # Not a Retweet\n",
        "        text = tweet.full_text\n",
        "#     print(f'Retweeted: {tweet.retweet_count}times')\n",
        "    tweets_list.append([tweet.user.screen_name, tweet.id, tweet.created_at, tweet.retweet_count, text])\n",
        "\n",
        "# populate dataframe with list of tweets specifying required column names\n",
        "tweet_df = pd.DataFrame(data=tweets_list, columns=['user','tweetid','created_at', 'retweet_count', 'text'])\n",
        "tweet_df\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T63PtWjEN2D8"
      },
      "source": [
        "## save the data into a csv file\n",
        "tweet_df.to_csv('ukmodelwho_tweet.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHp2Hm9L9pAi"
      },
      "source": [
        "You can save tweets in their original json format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KHQF3C-N2D8"
      },
      "source": [
        "user_id = \"UKModelWHO\"\n",
        "\n",
        "tweets = tweepy.Cursor(api.user_timeline, id=user_id ,lang=\"en\", include_rts=False, exclude_replies=True, tweet_mode='extended').items(10)\n",
        "\n",
        "filename = f\"{mypath}/tweets_{user_id}.jsons\"\n",
        "with open(filename, \"w\") as output:\n",
        "    for tweet in tweets:\n",
        "        myjson = tweet._json\n",
        "        output.write(json.dumps(myjson)+\"\\n\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2PhlHoa9pAi"
      },
      "source": [
        "Create dataframe from json files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGPEq6mejE7R"
      },
      "source": [
        "tweets_list = []\n",
        "\n",
        "filename = f\"{mypath}/tweets_{user_id}.jsons\"\n",
        "with open(filename) as fi:\n",
        "    for line_cnt, line in enumerate(fi):\n",
        "        tweet = json.loads(line)\n",
        "\n",
        "        tweet = json.loads(line.strip())\n",
        "\n",
        "        tweetid = tweet['id']\n",
        "        created_at = tweet['created_at']\n",
        "        \n",
        "        retweet_count = tweet['retweet_count']\n",
        "        # # # Extended Mode\n",
        "        if 'retweeted_status' in tweet: # If it's Retweet\n",
        "            text = tweet['retweeted_status']['full_text']\n",
        "        else:  # Not a Retweet\n",
        "            text = tweet['full_text']\n",
        "\n",
        "            \n",
        "        user_screen_name = tweet['user']['screen_name']\n",
        "\n",
        "        tweets_list.append([user_screen_name, tweetid, created_at, retweet_count, text])\n",
        "\n",
        "# populate dataframe with list of tweets specifying required column names\n",
        "tweet_df = pd.DataFrame(data=tweets_list, columns=['user','tweetid', 'created_at', 'retweet_count', 'text'])\n",
        "tweet_df\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mN2KUSCKPW28"
      },
      "source": [
        "## save the data into a tsv file (tab-separated)\n",
        "tweet_df.to_csv('ukmodelwho_tweet_simple_2.csv')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MS2InjZfjFea"
      },
      "source": [
        "#### Find the top three rows with highest retweet_count"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JBE07Q8KPW2-"
      },
      "source": [
        "df1 = tweet_df.sort_values('retweet_count',ascending = False).head(3)\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZVTEDi5PW2-"
      },
      "source": [
        "#### Filter out rows that have more than 2 rewteet_count\n",
        "\n",
        "You can filter dataframe by query(). See the official API from https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5ZQXygKPW2_"
      },
      "source": [
        "# Let's see how many rows the current dataframe has \n",
        "tweet_df.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa0KZ8zIPW2_"
      },
      "source": [
        "rt_tweet_df = tweet_df.query('retweet_count >= 2')\n",
        "print(rt_tweet_df.shape) # only half of the tweets have more than 2 retweet counts! (the value might be different to your case)\n",
        "rt_tweet_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lWHi4u-0PW2_"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6j9VR8zHPW2_"
      },
      "source": [
        "### Exercise 2\n",
        "\n",
        "Can you find the tweets with the highest favorites (likes)? \n",
        "\n",
        "Step 1: from JSON file, extract number of favorites of the tweet and add it to your dataframe.\n",
        "Step 2: Sort the rows based on likes and print the top 3. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cEEZZY6iPW2_"
      },
      "source": [
        "tweets_list = []\n",
        "\n",
        "filename = f\"{mypath}/tweets_{user_id}.jsons\"\n",
        "with open(filename) as fi:\n",
        "    for line_cnt, line in enumerate(fi):\n",
        "        tweet = json.loads(line)\n",
        "\n",
        "        tweet = json.loads(line.strip())\n",
        "\n",
        "        tweetid = tweet['id']\n",
        "        created_at = tweet['created_at']\n",
        "        \n",
        "        favorite_count = tweet['favorite_count']\n",
        "        # # # Extended Mode\n",
        "        if 'retweeted_status' in tweet: # If it's Retweet\n",
        "            text = tweet['retweeted_status']['full_text']\n",
        "        else:  # Not a Retweet\n",
        "            text = tweet['full_text']\n",
        "\n",
        "        user_screen_name = tweet['user']['screen_name']\n",
        "\n",
        "        tweets_list.append([user_screen_name, tweetid, created_at, favorite_count, text])\n",
        "\n",
        "# populate dataframe with list of tweets specifying required column names\n",
        "tweet_df_2 = pd.DataFrame(data=tweets_list, columns=['user','tweetid', 'created_at', 'favorite_count', 'text'])\n",
        "\n",
        "df1 = tweet_df_2.sort_values('favorite_count',ascending = False).head(3)\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8NAuESbPW2_"
      },
      "source": [
        "### Exercise 3 (Optional)\n",
        "\n",
        "Can you compute the correlation between two variables: favorite_count and retweet_count in the data? \n",
        "\n",
        "For computing the correlation for two variables, you can use ```scipy.stats.pearsonr``` function. \n",
        "\n",
        "Find more information about it [here](https://docs.scipy.org/doc/scipy-0.14.0/reference/generated/scipy.stats.pearsonr.html). \n",
        "\n",
        "Don't forget that you will need to import the library! \n",
        "```from scipy.stats.stats import pearsonr```\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SyqAUIX3PW2_"
      },
      "source": [
        "tweets_list = []\n",
        "\n",
        "filename = f\"{mypath}/tweets_{user_id}.jsons\"\n",
        "with open(filename) as fi:\n",
        "    for line_cnt, line in enumerate(fi):\n",
        "        tweet = json.loads(line)\n",
        "\n",
        "        tweet = json.loads(line.strip())\n",
        "\n",
        "        tweetid = tweet['id']\n",
        "        created_at = tweet['created_at']\n",
        "        \n",
        "        favorite_count = tweet['favorite_count']\n",
        "        retweet_count = tweet['retweet_count']\n",
        "        \n",
        "        # # # Extended Mode\n",
        "        if 'retweeted_status' in tweet: # If it's Retweet\n",
        "            text = tweet['retweeted_status']['full_text']\n",
        "        else:  # Not a Retweet\n",
        "            text = tweet['full_text']\n",
        "\n",
        "        user_screen_name = tweet['user']['screen_name']\n",
        "\n",
        "        tweets_list.append([user_screen_name, tweetid, created_at, retweet_count, favorite_count, text])\n",
        "\n",
        "# populate dataframe with list of tweets specifying required column names\n",
        "tweet_df_2 = pd.DataFrame(data=tweets_list, columns=['user','tweetid', 'created_at', 'retweet_count', 'favorite_count', 'text'])\n",
        "\n",
        "df1 = tweet_df_2.sort_values('favorite_count',ascending = False).head(3)\n",
        "df1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqohID9WPW2_"
      },
      "source": [
        "from scipy.stats.stats import pearsonr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZZwQKcBPW3A"
      },
      "source": [
        "pearsonr(df1['retweet_count'], df1['favorite_count'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYco8tbwPW3A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-3W9zqUk0xor"
      },
      "source": [
        "## 4) Streming API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UD_cwfQv04gL"
      },
      "source": [
        "Step 1: Creating a StreamListener\n",
        "\n",
        "`on_data()` is called when new data comes in\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SEoXjLD60xZ3"
      },
      "source": [
        "class MyStreamListener(tweepy.StreamListener):\n",
        "\n",
        "    \"\"\" A listener handles tweets are the received from the stream.\n",
        "    This is a basic listener that just prints received tweets to stdout.\n",
        "\n",
        "    \"\"\"\n",
        "    def on_data(self, data):\n",
        "        myjson=data[:-1]\n",
        "        myoutput.write(myjson+\"\\n\")\n",
        "        return True\n",
        "\n",
        "    def on_error(self, status):\n",
        "        print (\"Error\", status)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jux7RER92OV6"
      },
      "source": [
        "Step 2: Creating a Stream\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzHJkcfB2OAs"
      },
      "source": [
        "myStreamListener = MyStreamListener()\n",
        "myStream = tweepy.Stream(auth = api.auth, listener=myStreamListener, tweet_mode='extended')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp3EceDp9pAj"
      },
      "source": [
        "You need to stop the process before it collects too much data!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxctUZCUjFkH"
      },
      "source": [
        "keyword = 'covid'\n",
        "\n",
        "myfilename = f'{mypath}/stream_tweets_{keyword}.jsons'\n",
        "myoutput = open(myfilename, 'w')\n",
        "\n",
        "while True:\n",
        "    try:\n",
        "        # myStream.filter(track=['coronavirus', 'covid', 'chinese virus', 'wuhan', 'ncov', 'sars-cov-2', 'koronavirus', 'corona', 'cdc', 'N95', 'kungflu', 'epidemic', 'outbreak', 'sinophobia', 'china', 'pandemic', 'covd'])\n",
        "        myStream.filter(track=[keyword])\n",
        "\n",
        "    except Exception as e:\n",
        "        raise\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwKZLG_K25IR"
      },
      "source": [
        "outfilename = f\"{mypath}/simple_stream_tweets_{keyword}.tsv\" \n",
        "\n",
        "with open(myfilename) as fi, open(outfilename, 'w') as output:\n",
        "    # Write header in the file to load the file into dataframe\n",
        "    output.write(\"\\t\".join(['user_screen_name', 'tweetid', 'created_at', 'text'])+\"\\n\")\n",
        "    \n",
        "    for line_cnt, line in enumerate(fi):\n",
        "        try:\n",
        "            tweet = json.loads(line.strip())\n",
        "        except: # The last json is not complate \n",
        "            continue\n",
        "        \n",
        "        if 'limit' in tweet:\n",
        "            continue\n",
        "        \n",
        "        tweetid = tweet['id']\n",
        "        \n",
        "        created_at = tweet['created_at']\n",
        "        user_screen_name = tweet['user']['screen_name']\n",
        "\n",
        "        # Extract Tweet text from Streaming API when in Extended Mode \n",
        "        text = tweet['text']\n",
        "        try:\n",
        "            text = tweet['extended_tweet']['full_text']\n",
        "        except:\n",
        "            pass\n",
        "\n",
        "        # Below line will remove all tabs and line breaks from text\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        output.write(\"\\t\".join([user_screen_name, str(tweetid), created_at, text])+\"\\n\")\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g7fEXrhg7dKT"
      },
      "source": [
        "infilename = f\"{mypath}/simple_stream_tweets_{keyword}.tsv\" \n",
        "df = pd.read_csv(infilename, sep=\"\\t\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TA9rVXbiPW3B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MSGkFxCSPW3B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1If29S-EPW3B"
      },
      "source": [
        "## 4) Draw a word cloud\n",
        "\n",
        "A word cloud, which has been populary used as a tag cloud in the era of Blogs, is often used to show which words frequently appear. Detail explanations are available on https://en.wikipedia.org/wiki/Tag_cloud"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytr_v5w29pAk"
      },
      "source": [
        "!conda install --yes -c conda-forge wordcloud"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wcd9WVi89pAk"
      },
      "source": [
        "# Import relevant libraries\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPDNA_k7PW3B"
      },
      "source": [
        "#### Let's draw WordCloud of the collected tweets\n",
        "\n",
        "Loading a data into dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tjmtNtPiPW3B"
      },
      "source": [
        "infilename = f\"{mypath}/simple_stream_tweets_{keyword}.tsv\" \n",
        "df = pd.read_csv(infilename, sep=\"\\t\")\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_bI_YouPW3C"
      },
      "source": [
        "As WordCloud() function requires a **string** as a parameter, we need to concatenate all the rows of the 'text' column in the dataframe to a single string by join().\n",
        "\n",
        "This can be done in one line of code, \n",
        "```all_tweets = \" \".join(one_row for one_row in df['text'])```\n",
        "\n",
        "Let's disagreegate this code and check how it works."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T5cqZahtPW3C"
      },
      "source": [
        "# access 2nd item of df['text']\n",
        "df['text'][2]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeTOZ5MsPW3C"
      },
      "source": [
        "# access the first five rows of df['text']\n",
        "df['text'][:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOkdiE9RPW3C"
      },
      "source": [
        "# you can print the first 5 rows of df['text'] \n",
        "for one_row in df['text'][:5]:\n",
        "    print(one_row)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsiSejUTPW3C"
      },
      "source": [
        "# below will read the first 5 rows of df['text'] and reture as a list \n",
        "[one_row for one_row in df['text'][:5]]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTpe09LGPW3C"
      },
      "source": [
        "# how join function works, it concatenates items in the list and return a single sentence\n",
        "smaple = ['jisun is cool', 'michelle is cool', 'we all are cool']\n",
        "\" \".join(smaple)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-cKE_WxpPW3D"
      },
      "source": [
        "\" \".join([one_row for one_row in df['text'][:5]])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vukcwMdkPW3D"
      },
      "source": [
        "# this will concatenate all rows in df['text'] and return one single sentence!\n",
        "all_tweets = \" \".join([one_row for one_row in df['text']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5bwxYhz7c_D"
      },
      "source": [
        "# Enter your code to draw WordCloud\n",
        "wordcloud = WordCloud(stopwords=STOPWORDS, background_color=\"white\", width=1000, height=500).generate(all_tweets)\n",
        "\n",
        "# Display the generated image:\n",
        "plt.imshow(wordcloud, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y77TkMiSPW3D"
      },
      "source": [
        "We are curious about the context of 'vaccine'. \n",
        "You can search dataframe like below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_FURya-gPW3D"
      },
      "source": [
        "df[df[\"text\"].str.contains(\"vaccine\", na=False)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYmS_Fh8PW3D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv3fiB5CPW3D"
      },
      "source": [
        "## Exercise 3 - Let's compare two hashtags\n",
        "\n",
        "Hashtags are used when people discuss on certain topics or express their opinions. In this exercise, please collect tweets using two different hahstags that are opposing to each other, and then will draw wordcloud to compare the two datasets. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bm9mb-fPPW3D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2uIrfCvPW3D"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Gijq6e4PW3E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyf4oH9V9pAo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mFpHKQ5x9pAp"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YLBDhXbS9pAq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tzCAPde_PW3E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "on5CN8ZUPW3E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63fCRC2o9pAq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubeZcANQ9pAr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uuu2pP069pAr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}